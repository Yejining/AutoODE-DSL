{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from ode_nn import AutoODE_COVID, weight_fun\n",
    "from ode_nn import Dataset, train_epoch, eval_epoch, get_lr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "from ode_nn import Dataset_graph, train_epoch_graph, eval_epoch_graph, get_lr\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vislab/Yejin/AutoODE-DSL'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import join\n",
    "from pathlib import Path\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Preprocess the csv files from John Hopkins Dataset\n",
    "# https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports_us\n",
    "# direc = \".../ODEs/Data/COVID/\" # Directory that contains daily report csv files.\n",
    "direc = join(os.getcwd(), 'ODEs', 'Data', 'COVID')\n",
    "list_csv = sorted(os.listdir(direc))\n",
    "us = []\n",
    "for file in list_csv:\n",
    "    sample = pd.read_csv(join(direc, file)).set_index(\"Province_State\")[[\"Confirmed\", \"Recovered\", \"Deaths\"]].sort_values(by = \"Confirmed\", ascending = False)\n",
    "    us.append(sample.drop(['Diamond Princess', 'Grand Princess']))\n",
    "us = pd.concat(us, axis=1, join='inner')\n",
    "us_data = us.values.reshape(56,-1,3)\n",
    "us_data[us_data!=us_data] = 0\n",
    "\n",
    "#####################################################################################\n",
    "# Normalize by total population of each state\n",
    "population_path = join(os.getcwd(), 'ode_nn', 'population_states.csv')\n",
    "population = pd.read_csv(population_path, index_col=0)\n",
    "\n",
    "scaler = population.loc[us.index].values.reshape(56, 1, 1)*1e6\n",
    "us_data = us_data/scaler\n",
    "us_data = torch.from_numpy(us_data).float().to(device)\n",
    "\n",
    "# Mobility Data: beta = 1 - stay_at_home_percentages\n",
    "mobility_path = join(os.getcwd(), 'ode_nn', 'mobility')\n",
    "beta = torch.load(join(mobility_path, 'us_beta.pt')).float().to(device)\n",
    "\n",
    "# U.S states 1-0 Adjacency Matrix\n",
    "graph = torch.load(join(mobility_path,'us_graph.pt')).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train AutoODE-COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_519329/1088638814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"autoode-covid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0my_approx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0my_exact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "test_idx = 131\n",
    "\n",
    "# Learning Rate\n",
    "lr = 0.01\n",
    "\n",
    "# number of historic data points for fitting\n",
    "input_steps = 10 \n",
    "\n",
    "# forecasting horizon\n",
    "output_steps = 7\n",
    "\n",
    "# number of epochs for training\n",
    "num_epochs = 20000\n",
    "\n",
    "# select data for training\n",
    "data = us_data[:, test_idx-input_steps:test_idx+7].to(device)\n",
    "y_exact = data[:,:input_steps].to(device)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "model = AutoODE_COVID(initial_I = data[:,0,0], initial_R = data[:,0,1], initial_D = data[:,0,2],\n",
    "                      num_regions = 56, solver = \"RK4\", n_breaks = 1, graph = graph).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 1000, gamma=0.9)\n",
    "loss_fun = torch.nn.MSELoss().to(device)\n",
    "min_loss = 1\n",
    "\n",
    "##################################################################\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    scheduler.step()\n",
    "    y_approx = model(input_steps)\n",
    "    loss = loss_fun(y_approx[:,:,-3:], y_exact[:,:input_steps,-3:])\n",
    "    \n",
    "######## Weighted Loss ########\n",
    "#     loss_weight = weight_fun(input_steps, function = \"sqrt\", feat_weight = True)\n",
    "#     loss = torch.mean(loss_weight*loss_fun(y_approx[:,:,-3:], y_exact[:,:input_steps,-3:])) \n",
    "\n",
    "######## A few constraints that can potential improve the model ########\n",
    "#     positive_constraint = loss_fun(F.relu(-model.beta), torch.tensor(0.0).float().to(device))\n",
    "#     diagonal_constraint = loss_fun(torch.diagonal(model.A, 0),torch.tensor(1.0).float().to(device))\n",
    "#     initial_constraint = loss_fun(model.init_S + model.init_E + model.init_I + model.init_R + model.init_U, torch.tensor(1.0).float().to(device))\n",
    "#     loss += initial_constraint + positive_constraint + diagonal_constraint \n",
    "   \n",
    "    if loss.item() < min_loss:\n",
    "        best_model = model\n",
    "        min_loss = loss.item()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "#     if e%1000 == 0:\n",
    "#         y_approx2 = model(data.shape[1]).data.numpy()\n",
    "#         y_exact2 = data.data.numpy()\n",
    "#         print(list_csv[test_idx][:10])\n",
    "#         #torch.mean(torch.abs(y_approx - y_exact)[:,-7:]).data, torch.mean(torch.abs(y_approx - y_exact)[:,30:]).data\n",
    "#         for i in range(3):\n",
    "#             print(np.mean(np.abs(y_approx2*scaler - y_exact2*scaler)[:,-7:, i]))\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07-17-2020\n",
      "969.2932673160278\n",
      "450.2235062490256\n",
      "84.42754058480253\n"
     ]
    }
   ],
   "source": [
    "name = \"autoode-covid\"\n",
    "y_approx = best_model(data.shape[1]).data.cpu().numpy()\n",
    "y_exact = data.data.cpu().numpy()\n",
    "print(list_csv[test_idx][:10])\n",
    "#torch.mean(torch.abs(y_approx - y_exact)[:,-7:]).data, torch.mean(torch.abs(y_approx - y_exact)[:,30:]).data\n",
    "for i in range(3):\n",
    "    print(np.mean(np.abs(y_approx*scaler - y_exact*scaler)[:,-7:, i]))\n",
    "\n",
    "torch.save({\"model\": best_model,\n",
    "            \"preds\": y_approx*scaler,\n",
    "            \"trues\": y_exact*scaler},\n",
    "            \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.36255245e-03, 0.00000000e+00, 1.65246951e-04],\n",
       "       [7.56562036e-03, 3.71396425e-08, 1.65247402e-04],\n",
       "       [7.77083402e-03, 7.52946931e-08, 1.65247882e-04],\n",
       "       [7.97910150e-03, 1.14478070e-07, 1.65248392e-04],\n",
       "       [8.19132198e-03, 1.54707237e-07, 1.65248930e-04],\n",
       "       [8.40837788e-03, 1.96004052e-07, 1.65249512e-04],\n",
       "       [8.63113068e-03, 2.38394733e-07, 1.65250123e-04],\n",
       "       [8.86040926e-03, 2.81909706e-07, 1.65250778e-04],\n",
       "       [9.09699686e-03, 3.26583404e-07, 1.65251462e-04],\n",
       "       [9.34161339e-03, 3.72454025e-07, 1.65252190e-04],\n",
       "       [9.59490053e-03, 4.19563150e-07, 1.65252961e-04],\n",
       "       [9.85739846e-03, 4.67955317e-07, 1.65253776e-04],\n",
       "       [1.01295281e-02, 5.17677449e-07, 1.65254649e-04],\n",
       "       [1.04115717e-02, 5.68778262e-07, 1.65255566e-04],\n",
       "       [1.07036587e-02, 6.21307436e-07, 1.65256541e-04],\n",
       "       [1.10057555e-02, 6.75314936e-07, 1.65257559e-04],\n",
       "       [1.13176620e-02, 7.30850161e-07, 1.65258636e-04]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_approx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00736255, 0.        , 0.00016525],\n",
       "       [0.00757074, 0.        , 0.00016889],\n",
       "       [0.00781241, 0.        , 0.00017244],\n",
       "       [0.00802668, 0.        , 0.00017485],\n",
       "       [0.00820324, 0.        , 0.00017666],\n",
       "       [0.00834119, 0.        , 0.00017726],\n",
       "       [0.00857109, 0.        , 0.00017822],\n",
       "       [0.00888985, 0.        , 0.00018227],\n",
       "       [0.00910814, 0.        , 0.00018541],\n",
       "       [0.00935464, 0.        , 0.00018828],\n",
       "       [0.00958033, 0.        , 0.00019114],\n",
       "       [0.00976574, 0.        , 0.00019363],\n",
       "       [0.00991504, 0.        , 0.00019396],\n",
       "       [0.01019113, 0.        , 0.00019534],\n",
       "       [0.01046966, 0.        , 0.00019831],\n",
       "       [0.01076609, 0.        , 0.0002023 ],\n",
       "       [0.01099479, 0.        , 0.00020618]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_exact[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56, 17, 3), (56, 17, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_approx.shape, y_exact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DeepNIPA)",
   "language": "python",
   "name": "deepnipa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
